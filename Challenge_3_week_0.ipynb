{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "criminal-logic",
   "metadata": {},
   "source": [
    "# Topic Modeling and sentiment analaysis\n",
    "\n",
    "## Topic modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "selected-sitting",
   "metadata": {},
   "source": [
    "Topic Models, in a nutshell, are a type of statistical language models used for uncovering hidden structure in a collection of texts. In a practical and more intuitively, you can think of it as a task of:\n",
    "\n",
    "Dimensionality Reduction, where rather than representing a text T in its feature space as {Word_i: count(Word_i, T) for Word_i in Vocabulary}, you can represent it in a topic space as {Topic_i: Weight(Topic_i, T) for Topic_i in Topics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-adapter",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integrated-investigator",
   "metadata": {},
   "source": [
    "Sentiment analysis\n",
    "It is used in social media monitoring, allowing businesses to gain insights about how customers feel about certain topics, and detect urgent issues in real time before they spiral out of control.\n",
    "\n",
    "Our task here is to classify a tweet as a positive or negative tweet sentiment wise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instant-lightning",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "There are several existing algorithms we can use to perform the topic modeling. The most common of it are, Latent Semantic Analysis (LSA/LSI), Probabilistic Latent Semantic Analysis (pLSA), and Latent Dirichlet Allocation (LDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unable-muscle",
   "metadata": {},
   "source": [
    "\n",
    "In this article, weâ€™ll take a closer look at LDA, and implement our first topic model using the sklearn implementation in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continent-commonwealth",
   "metadata": {},
   "source": [
    "# LDA Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-annual",
   "metadata": {},
   "source": [
    "The steps used to implement LDA :\n",
    "   1) Loading data\n",
    "   \n",
    "   2) Data cleaning\n",
    "   \n",
    "   \n",
    "   3) Exploratory analysis\n",
    "   \n",
    "   \n",
    "   4) Preparing data for LDA analysis\n",
    "   \n",
    "   \n",
    "   5) LDA model training\n",
    "   \n",
    "   \n",
    "   6) Analyzing LDA model results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "induced-norway",
   "metadata": {},
   "source": [
    "# Step 1: Loading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "pressed-combat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fri Jun 18 17:55:49 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>ðŸš¨Africa is \"in the midst of a full-blown third...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>en</td>\n",
       "      <td>548</td>\n",
       "      <td>612</td>\n",
       "      <td>ketuesriche</td>\n",
       "      <td>551</td>\n",
       "      <td>351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'TelGlobalHealth', 'name': 'T...</td>\n",
       "      <td>Mass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri Jun 18 17:55:59 +0000 2021</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Dr Moeti is head of WHO in Africa, and one of ...</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.455556</td>\n",
       "      <td>en</td>\n",
       "      <td>195</td>\n",
       "      <td>92</td>\n",
       "      <td>Grid1949</td>\n",
       "      <td>66</td>\n",
       "      <td>92</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'globalhlthtwit', 'name': 'An...</td>\n",
       "      <td>Edinburgh, Scotland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fri Jun 18 17:56:07 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>Thank you @research2note for creating this ama...</td>\n",
       "      <td>0.316667</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>en</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>LeeTomlinson8</td>\n",
       "      <td>1195</td>\n",
       "      <td>1176</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'text': 'red4research', 'indices': [103, 116]}]</td>\n",
       "      <td>[{'screen_name': 'NHSRDForum', 'name': 'NHS R&amp;...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fri Jun 18 17:56:10 +0000 2021</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>Former Pfizer VP and Virologist, Dr. Michael Y...</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>0.197222</td>\n",
       "      <td>en</td>\n",
       "      <td>1580</td>\n",
       "      <td>899</td>\n",
       "      <td>RIPNY08</td>\n",
       "      <td>2666</td>\n",
       "      <td>2704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'HighWireTalk', 'name': 'The ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fri Jun 18 17:56:20 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>I think itâ€™s important that we donâ€™t sell COVA...</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>en</td>\n",
       "      <td>72</td>\n",
       "      <td>20</td>\n",
       "      <td>pash22</td>\n",
       "      <td>28250</td>\n",
       "      <td>30819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'screen_name': 'PeterHotez', 'name': 'Prof P...</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at  \\\n",
       "0  Fri Jun 18 17:55:49 +0000 2021   \n",
       "1  Fri Jun 18 17:55:59 +0000 2021   \n",
       "2  Fri Jun 18 17:56:07 +0000 2021   \n",
       "3  Fri Jun 18 17:56:10 +0000 2021   \n",
       "4  Fri Jun 18 17:56:20 +0000 2021   \n",
       "\n",
       "                                              source  \\\n",
       "0  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "1  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "2  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "3  <a href=\"https://mobile.twitter.com\" rel=\"nofo...   \n",
       "4  <a href=\"http://twitter.com/download/android\" ...   \n",
       "\n",
       "                                       original_text  polarity  subjectivity  \\\n",
       "0  ðŸš¨Africa is \"in the midst of a full-blown third...  0.166667      0.188889   \n",
       "1  Dr Moeti is head of WHO in Africa, and one of ...  0.133333      0.455556   \n",
       "2  Thank you @research2note for creating this ama...  0.316667      0.483333   \n",
       "3  Former Pfizer VP and Virologist, Dr. Michael Y...  0.086111      0.197222   \n",
       "4  I think itâ€™s important that we donâ€™t sell COVA...  0.280000      0.620000   \n",
       "\n",
       "  lang  favorite_count  retweet_count original_author  followers_count  \\\n",
       "0   en             548            612     ketuesriche              551   \n",
       "1   en             195             92        Grid1949               66   \n",
       "2   en               2              1   LeeTomlinson8             1195   \n",
       "3   en            1580            899         RIPNY08             2666   \n",
       "4   en              72             20          pash22            28250   \n",
       "\n",
       "   friends_count possibly_sensitive  \\\n",
       "0            351                NaN   \n",
       "1             92                NaN   \n",
       "2           1176                NaN   \n",
       "3           2704                NaN   \n",
       "4          30819                NaN   \n",
       "\n",
       "                                            hashtags  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  [{'text': 'red4research', 'indices': [103, 116]}]   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                       user_mentions                place  \n",
       "0  [{'screen_name': 'TelGlobalHealth', 'name': 'T...                 Mass  \n",
       "1  [{'screen_name': 'globalhlthtwit', 'name': 'An...  Edinburgh, Scotland  \n",
       "2  [{'screen_name': 'NHSRDForum', 'name': 'NHS R&...                  NaN  \n",
       "3  [{'screen_name': 'HighWireTalk', 'name': 'The ...                  NaN  \n",
       "4  [{'screen_name': 'PeterHotez', 'name': 'Prof P...       United Kingdom  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing modules\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import STOPWORDS,WordCloud\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "\n",
    "#os.chdir('..')\n",
    "\n",
    "# Read data into papers\n",
    "papers = pd.read_csv('week_0_challenge_3/processed_tweet_data .csv')\n",
    "\n",
    "# Print head\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "published-firmware",
   "metadata": {},
   "source": [
    "# Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-saturday",
   "metadata": {},
   "source": [
    "Since the goal of this analysis is to perform topic modeling, let's focus only on the text data from each paper, and drop other metadata columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "intensive-appeal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>source</th>\n",
       "      <th>original_text</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>lang</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>original_author</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>place</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>Sat Jun 19 03:48:23 +0000 2021</td>\n",
       "      <td>&lt;a href=\"https://help.twitter.com/en/using-twi...</td>\n",
       "      <td>Pin Code:[411040] \\nChatrapati Shahu Maharaj P...</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>PuneUpdater</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1117</th>\n",
       "      <td>Fri Jun 18 19:21:12 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>@AIPAC Will aipac tell the world that Israel h...</td>\n",
       "      <td>-0.125000</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>en</td>\n",
       "      <td>28</td>\n",
       "      <td>Cavill08</td>\n",
       "      <td>227</td>\n",
       "      <td>261</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2867</th>\n",
       "      <td>Fri Jun 18 22:39:46 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
       "      <td>Former Pfizer VP and Virologist, Dr. Michael Y...</td>\n",
       "      <td>0.086111</td>\n",
       "      <td>0.197222</td>\n",
       "      <td>en</td>\n",
       "      <td>904</td>\n",
       "      <td>scott48_scott</td>\n",
       "      <td>62</td>\n",
       "      <td>64</td>\n",
       "      <td>[]</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>Fri Jun 18 20:17:14 +0000 2021</td>\n",
       "      <td>&lt;a href=\"https://help.twitter.com/en/using-twi...</td>\n",
       "      <td>Novavax says COVID-19 vaccine highly effective...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>en</td>\n",
       "      <td>0</td>\n",
       "      <td>CanNews24</td>\n",
       "      <td>180</td>\n",
       "      <td>448</td>\n",
       "      <td>[]</td>\n",
       "      <td>Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3864</th>\n",
       "      <td>Sat Jun 19 01:15:34 +0000 2021</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
       "      <td>You can get a #COVID19 vaccine and other vacci...</td>\n",
       "      <td>0.093750</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>en</td>\n",
       "      <td>128</td>\n",
       "      <td>HenryARose</td>\n",
       "      <td>385</td>\n",
       "      <td>492</td>\n",
       "      <td>[{'text': 'COVID19', 'indices': [26, 34]}]</td>\n",
       "      <td>Pembroke Pines, Florida, USA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          created_at  \\\n",
       "4949  Sat Jun 19 03:48:23 +0000 2021   \n",
       "1117  Fri Jun 18 19:21:12 +0000 2021   \n",
       "2867  Fri Jun 18 22:39:46 +0000 2021   \n",
       "1698  Fri Jun 18 20:17:14 +0000 2021   \n",
       "3864  Sat Jun 19 01:15:34 +0000 2021   \n",
       "\n",
       "                                                 source  \\\n",
       "4949  <a href=\"https://help.twitter.com/en/using-twi...   \n",
       "1117  <a href=\"http://twitter.com/download/android\" ...   \n",
       "2867  <a href=\"http://twitter.com/download/android\" ...   \n",
       "1698  <a href=\"https://help.twitter.com/en/using-twi...   \n",
       "3864  <a href=\"http://twitter.com/download/iphone\" r...   \n",
       "\n",
       "                                          original_text  polarity  \\\n",
       "4949  Pin Code:[411040] \\nChatrapati Shahu Maharaj P... -0.750000   \n",
       "1117  @AIPAC Will aipac tell the world that Israel h... -0.125000   \n",
       "2867  Former Pfizer VP and Virologist, Dr. Michael Y...  0.086111   \n",
       "1698  Novavax says COVID-19 vaccine highly effective...  0.600000   \n",
       "3864  You can get a #COVID19 vaccine and other vacci...  0.093750   \n",
       "\n",
       "      subjectivity lang  retweet_count original_author  followers_count  \\\n",
       "4949      1.000000   en              0     PuneUpdater               89   \n",
       "1117      0.725000   en             28        Cavill08              227   \n",
       "2867      0.197222   en            904   scott48_scott               62   \n",
       "1698      0.800000   en              0       CanNews24              180   \n",
       "3864      0.281250   en            128      HenryARose              385   \n",
       "\n",
       "      friends_count                                    hashtags  \\\n",
       "4949              0                                          []   \n",
       "1117            261                                          []   \n",
       "2867             64                                          []   \n",
       "1698            448                                          []   \n",
       "3864            492  [{'text': 'COVID19', 'indices': [26, 34]}]   \n",
       "\n",
       "                             place  \n",
       "4949                           NaN  \n",
       "1117                           NaN  \n",
       "2867                 United States  \n",
       "1698                        Canada  \n",
       "3864  Pembroke Pines, Florida, USA  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the columns\n",
    "papers = papers.drop(columns=['favorite_count','possibly_sensitive','user_mentions'], axis=1).sample(100)\n",
    "# Print out the first rows of papers\n",
    "papers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-psychology",
   "metadata": {},
   "source": [
    "## Remove punctuation/lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the regular expression library\n",
    "import re\n",
    "\n",
    "# Remove punctuation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-entrepreneur",
   "metadata": {},
   "source": [
    "# Step 3: Exploratory Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-webster",
   "metadata": {},
   "source": [
    "To verify whether the preprocessing, weâ€™ll make a word cloud using the wordcloud package to get a visual representation of most common words. It is key to understanding the data and ensuring we are on the right track, and if any more preprocessing is necessary before training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "british-breeding",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'paper_text_processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'paper_text_processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-52ada90046d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Join the different processed titles together.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlong_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpapers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paper_text_processed'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a WordCloud object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackground_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"white\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontour_width\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontour_color\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steelblue'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'paper_text_processed'"
     ]
    }
   ],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(papers['paper_text_processed'].values))\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "august-memorial",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
